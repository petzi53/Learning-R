---
title: "OpenIntro Statistics: Introduction to data"
author: Peter Baumgartner
date: 2017-02-02
output: 
     html_notebook:
        number_sections: yes
        toc: yes
        toc_depth: 6
---

```{r label = "global-options", echo=FALSE, highlight=TRUE}
knitr::opts_chunk$set(
        message = F,
        error = F,
        warning = F,
        comment = NA,
        highlight = T,
        prompt = T,
        cached = T
        )
```

# Getting started
## Supplementary material

I am using this file to explore the first chapter "Introduction to data" of [OpenIntro Statistics](https://www.openintro.org/stat/textbook.php?stat_book=os). The textbooks comes with many additional material:

* [Videos](https://www.openintro.org/stat/videos.php)
* Many Exercises at the end of the chapters: With solution of all odd-numbered in the annex. (But one can apply as teacher to get all solutions)
* [Interactive Labs with R](https://www.openintro.org/stat/labs.php)
* Several R Packages:
    + [openintro](https://cran.r-project.org/web/packages/openintro/index.html): OpenIntro data sets and supplemental functions. [PDF manual](https://cran.r-project.org/web/packages/openintro/openintro.pdf))
    + [OIdata](https://cran.r-project.org/web/packages/OIdata/index.html): Data sets and supplements (OpenIntro). [PDF manual](https://cran.r-project.org/web/packages/OIdata/OIdata.pdf)
    + [oilabs](https://github.com/OpenIntroOrg/oilabs) An R package that contains the data sets, custom functions, documentation, and templates for the OpenIntro Labs.
* [Free course on datacamp.com](https://www.datacamp.com/community/open-courses/statistical-inference-and-data-analysis) Data Analysis and Statistical Inference
* Github source files to work interactively:
    + [OpenIntro Statistics labs with base R](https://github.com/andrewpbray/oiLabs-base-R): Contentrates on base R functions and packages
    + [OpenIntro Statistics labs with dplyr and ggplot2](https://github.com/andrewpbray/oiLabs-base-R): OpenIntro Labs in R using the dplyr and ggplot2 syntax for data manipulation.
* [Coursera](https://www.coursera.org/specializations/statistics#courses): And last not least there is also a Coursera course specialisation (5 courses).

## My learning strategies                
I plan to take the chapters in several overlapping rounds:

* I will follow the text and experiment with the data on my own. Here I will give special attention in using function from the tidyverse-packages.
* I will follow the text for the R labs
* And I will complete the course on Datacam.com.

I am not sure, if this various approaches are effective or too much of the same. But I will at least try out all of these different learning possiblities. 

I will start with the [github labs tutorial](http://htmlpreview.github.io/?https://github.com/andrewpbray/oiLabs-base-R/blob/master/intro_to_data/intro_to_data.html).

# Data basics
## Get the data

The Behavioral Risk Factor Surveillance System (BRFSS) is an annual telephone survey of 350,000 people in the United States. The [BRFSS Web site](http://www.cdc.gov/brfss) contains a complete description of the survey, including the research questions that motivate the study and many interesting results derived from the data.

Load the data set from the [OpenIntro Website](http://www.openintro.org/stat/data/cdc.R). 

* Have a look at the data in the browser to get a feeling of the raw data.
* Load the data set into R. As it is a big file (2.1 MB) check if it is already loaded into memory:
```{r get-cdc-data}
if (!exists("cdc")) {source("http://www.openintro.org/stat/data/cdc.R")}
```
The data set `cdc` that shows up in your workspace is a data matrix, with each row representing a case and each column representing a variable. R calls this data format a data frame, which is a term that will be used throughout the labs. 

But I will convert all data frames into to a `tibbles`. This has some advantages, explained in [R for Data Science](http://r4ds.had.co.nz/tibbles.html)

* It never changes an input’s type (i.e., no more stringsAsFactors = FALSE!).
* It never adjusts the names of variables (i.e. you can create names with blanks)
* It evaluates its arguments lazily and sequentially (i.e. you can calculate `y` from values of x during the creation)
* It never uses `row.names()`. The whole point of tidy data is to store variables in a consistent way. So it never stores a variable as special attribute.
* It only recycles vectors of length 1. This is because recycling vectors of greater lengths is a frequent source of bugs.
* When you print a tibble, it only shows the first ten rows and all the columns that fit on one screen. It also prints an abbreviated description of the column type.
* Tibbles are quite strict about subsetting. `[` always returns another tibble whereas d data frame sometimes returns a data frame and sometimes it just returns a vector.
* Tibbles are also stricter with $. as they never do partial matching (a common source of error).
* Tibbles ignore the drop argument.

Therefore I will call the matrix organisation of the data set "tibble" or abbreviated "tbl".


```{r covert-df-into-tibble}
library(tidyverse)
CDC <- tbl_df(cdc)
class(cdc)
class(CDC)
```
"cdc" (with small letters) has class "`r class(cdc)`", whereas "CDC" (with capital letters) now have "`r class(CDC)`" e.g. three classes at the same time to secure full compatiblity with data frames. 

## Explore the data
After loading the data and converting it into a tibble, one should inspect the data to get some understanding about the structure and content. Common funtions for these tasks are:

* `<name-of-data-tibble>`: Display the first 10 rows and all columns that fit on one screen. It also prints an abbreviated description of the column type.
* `head(<name-of-df>)`, `tail(<name-of-df>)`: Return the first or last part. Use these commands if it is not a tibble but a data frame
* `dim()`: Retrieve the dimension
* `names()`: Get the names
* `str()`: Display compactly the internal structure
* `glimpse()`: is the `dplyr`-version of `str()` showing values of each variable the whole sceen width, but does not display the number of levels and names of factor variables. But this feature of `str()` cannot be displayed completly with either many or long levels names.
* `View()`: With [RStudio](https://www.rstudio.com/) you can see and inspect the data set comfortably. The `View()` function invokes a spreadsheet-style data viewer.

You can see and inspect the data set comfortably in RStudio with the `View()` command, which invokes a spreadsheet-style data viewer on a matrix-like R object.
```{r explore-data-set}
CDC
head(CDC)
tail(CDC)
dim(CDC)
names(CDC)
str(CDC)
glimpse(CDC)
# View(CDC)
```

The tibble has 2000 observations (= rows) with 9 variables (columns). Each one of these variables corresponds to a question that was asked in the survey:

1. `genhlth`: respondents were asked to evaluate their general health, responding either excellent, very good, good, fair or poor. 
2. `exerany`: indicates whether the respondent exercised in the past month (1) or did not (0).
3. `hlthplan`: indicates whether the respondent had some form of health coverage (1) or did not (0). 
4. `smoke100`: indicates whether the respondent had smoked at least 100 cigarettes in her lifetime. 
5. `height`: in inches
6. `weight`: in pounds 
7. `wtdesire`: desired weight 
8. `age` in years
9. `gender`: "m" or "f"

Exercise 1
: How many cases are there in this data set? How many variables? For each variable, identify its data type (e.g. categorical, discrete).

**My Solution**: 

 0. There are `r nrow(CDC)` cases (= observations) and `r ncol(CDC)` variables in the CDC data set.

1. `genhlth`: excellent, very good, good, fair or poor = categorial
2. `exerany`: past month (1) or not (0) = categorial
3. `hlthplan`: some form of health coverage (1) or not (0) = categorial
4. `smoke100`: had smoked at least 100 cigarettes in her lifetime = categorial
5. `height`: in inches = continous
6. `weight`: in pounds = continous
7. `wtdesire`: desired weight = continuos
8. `age` in years = discrete
9. `gender`: "m" or "f" = categorial

# Summaries and tables
A good first step in any analysis is to distill all of that information into a few summary statistics and graphics. As a simple example, the function summary returns a numerical summary: minimum, first quartile, median, mean, second quartile, and maximum. For weight this is:
```{r summary-of-weight}
summary(CDC$weight)
```
`dplyr` does not have its own special methods for R summary function (see last sentence of vignette [Introduction to dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html). But you can use the R base functions with `dplyr` and some other extra functions supplied by `dplyr`. Besides functions in base R like `min()`, `max()`, `mean()`, `sum()`, `sd()`, `median()`, and `IQR()`. dplyr provides a handful of others:

* `n()`: the number of observations in the current group
* `n_distinct(x)`:the number of unique values in x.
* `first(x)`, `last(x)` and `nth(x, n) - these work similarly to x[1], x[length(x)], and x[n] but give you more control over the result if the value is missing.
```{r dplyr-equivalent-of-summarise}
summarise(CDC, Min. = min(weight), "1st Qu." = quantile(weight, probs = 0.25), Median = median(weight), Mean = mean(weight), "3rd Qu." = quantile(weight, probs = 0.75), Max = max(weight))
```
The `dplyr`-equivalent of base R `summary()` is more complex, but has more control about functions used, their names in the table, their sequence etc. So we could add for instance `sd()`, `var()`, `IQR()`. To get these extra values with the base R functions one would have to be write different lines of code.
```{r dplyr-summarise-many-statistics}
summarise(CDC, Min. = min(weight), "1st Qu." = quantile(weight, probs = 0.25), Median = median(weight), Mean = mean(weight), "3rd Qu." = quantile(weight, probs = 0.75), Max = max(weight), Var = var(weight), SD = sd(weight), IQR = IQR(weight))
```
But the great advantage for `summarise()` lies int the combination with the `group_by()` function of `dplyr` (see the examples in the [Introduction to dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) vignette.)

While it makes sense to describe a quantitative variable like `weight` in terms of these statistics, what about categorical data? We would instead consider the sample frequency or relative frequency distribution. The function table does this for you by counting the number of times each kind of response was given. For example, to see the number of people who have smoked 100 cigarettes in their lifetime or instead look at the relative frequency distribution.
```{r generate-contingency-tables-with-base-r-table}
table(CDC$smoke100)
table(CDC$smoke100) / 20000
```
Notice how R automatically divides all entries in the table by 20,000 in the command above. This is similar to something we observed in the Introduction to R; when we multiplied or divided a vector with a number, R applied that action across entries in the vectors. As we see above, this also works for tables.

But the outcome of the `table()` command is class "`r class(table(CDC$smoke100))`" which is not so easy to work with as a data frame or a tibble. (See the article on [R-bloggers](https://www.r-bloggers.com/how-to-get-the-frequency-table-of-a-categorical-variable-as-a-data-frame-in-r/).) It is better to use the `count()` function of `dplyr`, because it adds the column names and returns – as all dply-functions — a tibble. Furthermore the relative frequency distribution (the propoartion) can be added as a new column in one command.
```{r generate-contingency-tables-with-dplyr-count}
CDC %>% 
        count(smoke100) %>%
        mutate(prop = n / 20000)

```


Next, we make a bar plot of the entries in the table by putting the table inside the `barplot()` command.
```{r generate-a-barplot}
barplot(table(CDC$smoke100))
```
Notice what we’ve done here! We’ve computed the table of cdc$smoke100 and then immediately applied the graphical function, barplot. This is an important idea: R commands can be nested. You could also break this into two steps by typing the following:

```{r generate-a-barplot-from-a-table-object}
smoke <- table(CDC$smoke100)

barplot(smoke)
```

Here, we’ve made a new object, a table, called `smoke` (the contents of which we can see by typing `smoke` into the console) and then used it in as the input for barplot. The special symbol `<-` performs an assignment, taking the output of one line of code and saving it into an object in your workspace.

```{r}
tbl(CDC, smoke100)

```

